{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"run.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"D_1vzIZIa97E"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BF5ov2i8melX","executionInfo":{"status":"ok","timestamp":1651371677410,"user_tz":240,"elapsed":873,"user":{"displayName":"Utsav Dutta","userId":"03651138194545313143"}},"outputId":"d1dfa2de-5545-4f27-a6d1-e6f3425c45ee"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/.shortcut-targets-by-id/1mLIpKobxLqDPVzGz-XXAA4JO-lEjQbax/10707/src\n"]}],"source":["cd drive/MyDrive/10707/src"]},{"cell_type":"code","source":["## Import Libraries\n","\n","import models\n","from models import *\n","\n","import dataset\n","from dataset import *\n","\n","import optimizer\n","from optimizer import *\n","\n","import utils \n","from utils import *\n","\n","import train \n","from train import *\n","\n","import pickle"],"metadata":{"id":"-Xy4uzEcmfkO","executionInfo":{"status":"ok","timestamp":1651371683831,"user_tz":240,"elapsed":6428,"user":{"displayName":"Utsav Dutta","userId":"03651138194545313143"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["## Import Data\n","\n","with open(\"data/EEG_Moabb.pickle\",\"rb\") as f:\n","  data_for_EEG = pickle.load(f)"],"metadata":{"id":"Ummc2dW5orq2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data_for_EEG[1][0].shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1UoGia-IZCTG","executionInfo":{"status":"ok","timestamp":1651354503536,"user_tz":240,"elapsed":8,"user":{"displayName":"Utsav Dutta","userId":"03651138194545313143"}},"outputId":"c0475027-313d-455d-9b09-f2152f52d979"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(90, 64, 481)"]},"metadata":{},"execution_count":14}]},{"cell_type":"code","source":["## Build Dataset\n","\n","dataset = EEGBiometricDataset(list(range(1,40)),data_for_EEG)\n","n_classes = dataset.num_subjects()"],"metadata":{"id":"l57lmP5xodxT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["## Split Into Train and Test\n","\n","train_dataset, test_dataset = create_train_test(dataset,split = 0.8)\n","train_loader, test_loader = create_loaders(train_dataset,test_dataset,batch_size=32)"],"metadata":{"id":"KnRut2-Rp0SQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["## Initiliaze Model\n","\n","# model = EEGFusionNet()\n","n_classes = 39\n","model = EEGBiometricNet(n_classes)\n","model.cuda()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DoxPNzGtmqyN","executionInfo":{"status":"ok","timestamp":1651371712407,"user_tz":240,"elapsed":9511,"user":{"displayName":"Utsav Dutta","userId":"03651138194545313143"}},"outputId":"61bcd889-5485-46e7-a0f4-5abf6c0fde22"},"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["EEGBiometricNet(\n","  (conv1): Conv2d(1, 16, kernel_size=(1, 64), stride=(1, 1))\n","  (avgpool1): AvgPool2d(kernel_size=(1, 8), stride=(1, 8), padding=0)\n","  (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (conv2): Conv2d(16, 32, kernel_size=(32, 2), stride=(1, 1))\n","  (avgpool2): AvgPool2d(kernel_size=(1, 8), stride=(1, 8), padding=0)\n","  (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (linear1): Linear(in_features=1056, out_features=64, bias=True)\n","  (linear3): Linear(in_features=64, out_features=39, bias=True)\n",")"]},"metadata":{},"execution_count":7}]},{"cell_type":"code","source":["import torchsummary\n","from torchsummary import summary"],"metadata":{"id":"YDxK49ZWbEw6","executionInfo":{"status":"ok","timestamp":1651371767723,"user_tz":240,"elapsed":270,"user":{"displayName":"Utsav Dutta","userId":"03651138194545313143"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["summary(model,(1,64,160))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"scQC8RUUbXNe","executionInfo":{"status":"ok","timestamp":1651371785117,"user_tz":240,"elapsed":841,"user":{"displayName":"Utsav Dutta","userId":"03651138194545313143"}},"outputId":"92c41fa1-e36c-4284-aa96-3ae4d04bfcb4"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Conv2d-1           [-1, 16, 64, 97]           1,040\n","         AvgPool2d-2           [-1, 16, 64, 12]               0\n","       BatchNorm2d-3           [-1, 16, 64, 12]              32\n","            Conv2d-4           [-1, 32, 33, 11]          32,800\n","         AvgPool2d-5            [-1, 32, 33, 1]               0\n","       BatchNorm2d-6            [-1, 32, 33, 1]              64\n","            Linear-7                   [-1, 64]          67,648\n","            Linear-8                   [-1, 39]           2,535\n","================================================================\n","Total params: 104,119\n","Trainable params: 104,119\n","Non-trainable params: 0\n","----------------------------------------------------------------\n","Input size (MB): 0.04\n","Forward/backward pass size (MB): 1.05\n","Params size (MB): 0.40\n","Estimated Total Size (MB): 1.49\n","----------------------------------------------------------------\n"]}]},{"cell_type":"code","source":["## Create Optimizer\n","\n","optimizer = build_optimizer(model,'adam',3e-4)\n","scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer,patience=5,factor=0.5)"],"metadata":{"id":"CMpjQ3Gzm5sx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model,optimizer = train(model,optimizer,train_loader,test_loader,num_epochs=100,scheduler=scheduler)"],"metadata":{"id":"S4F_-4W3q695","colab":{"base_uri":"https://localhost:8080/","height":433},"executionInfo":{"status":"error","timestamp":1651107758759,"user_tz":240,"elapsed":418,"user":{"displayName":"Utsav Dutta","userId":"03651138194545313143"}},"outputId":"89ab5925-84b3-4fbb-dfa4-b5bf38e51d39"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Train Dataset 8424\n","Test Dataset 2106\n","\n"," Model Name :  EEGFusionNet \n","\n"]},{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-10-09819a2aef2c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mscheduler\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscheduler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/content/drive/.shortcut-targets-by-id/1mLIpKobxLqDPVzGz-XXAA4JO-lEjQbax/10707/src/train.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, optimizer, train_loader, test_loader, num_epochs, criterion, scheduler, verbose)\u001b[0m\n\u001b[1;32m     35\u001b[0m       \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m       \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m           \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/drive/.shortcut-targets-by-id/1mLIpKobxLqDPVzGz-XXAA4JO-lEjQbax/10707/src/models.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    242\u001b[0m     \u001b[0mx1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblock1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m     \u001b[0mx2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 244\u001b[0;31m     \u001b[0mx3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblock3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    245\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/drive/.shortcut-targets-by-id/1mLIpKobxLqDPVzGz-XXAA4JO-lEjQbax/10707/src/models.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 207\u001b[0;31m     \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgru\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    208\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    941\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    942\u001b[0m             result = _VF.gru(input, hx, self._flat_weights, self.bias, self.num_layers,\n\u001b[0;32m--> 943\u001b[0;31m                              self.dropout, self.training, self.bidirectional, self.batch_first)\n\u001b[0m\u001b[1;32m    944\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    945\u001b[0m             result = _VF.gru(input, batch_sizes, hx, self._flat_weights, self.bias,\n","\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 250.00 MiB (GPU 0; 14.76 GiB total capacity; 13.40 GiB already allocated; 41.75 MiB free; 13.48 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"]}]},{"cell_type":"code","source":["torch.save(model.state_dict(), \"saved_models/BiometricNet.pth\")"],"metadata":{"id":"JUW3bwAmsHPC"},"execution_count":null,"outputs":[]}]}